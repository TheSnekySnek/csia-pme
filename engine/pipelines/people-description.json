{
  "type": "pipeline",
  "nodes": [
    {
      "type": "entry",
      "id": "faceDescrEntry",
      "api": {
        "summary": "Describe the people in an image.",
        "route": "describe-faces",
        "body": "image"
      },
      "next": [
        "analyzeImg"
      ]
    },
    {
      "type": "service",
      "id": "analyzeImg",
      "url": "http://service-image-processing.project-dev.svc.cluster.local/analyze",
      "input": {
        "image": "faceDescrEntry.out.image"
      },
      "next": [
        "checkFormat"
      ]
    },
    {
      "id": "checkFormat",
      "input": {
        "imgMime": "analyzeImg.out.format"
      },
      "type": "branch",
      "if": "input.imgMime != 'image/jpeg'",
      "then": {
        "next": [
          "convert"
        ]
      },
      "else": {
        "next": [
          "imageOk"
        ],
        "out": {
          "result": "faceDescrEntry.out.image"
        }
      }
    },
    {
      "type": "service",
      "id": "convert",
      "params": {
        "format": "jpeg",
        "quality": 90
      },
      "url": "http://service-image-processing.project-dev.svc.cluster.local/convert",
      "input": {
        "image": "faceDescrEntry.out.image",
        "format": "node.params.format",
        "quality": "node.params.quality"
      },
      "next": [
        "imageOk"
      ]
    },
    {
      "type": "node",
      "id": "imageOk",
      "ready": "checkFormat.finished or convert.finished",
      "next": [
        "detectFaces"
      ]
    },
    {
      "type": "service",
      "id": "detectFaces",
      "url": "http://service-face-detection.project-dev.svc.cluster.local/compute",
      "input": {
        "image": "imageOk.out.result"
      },
      "next": [
        "loopFaces"
      ]
    },
    {
      "type": "loop",
      "id": "loopFaces",
      "items": "detectFaces.out.answer",
      "next": [
        "describe"
      ],
      "nodes": [
        {
          "type": "node",
          "id": "faceZone",
          "after": "borderw = int((node._loop[2] - node._loop[0]) / 5)\nborderh = int((node._loop[3] - node._loop[1]) / 5)\nnode.out['areas'] = [[node._loop[0] - borderw, node._loop[1] - borderh, node._loop[2] + borderw, node._loop[3] + borderh]]",
          "next": [
            "cropFace"
          ]
        },
        {
          "type": "service",
          "id": "cropFace",
          "url": "http://service-image-processing.project-dev.svc.cluster.local/crop",
          "input": {
            "image": "imageOk.out.result",
            "areas": "loop.faceZone.out.areas"
          },
          "next": [
            "analyzeFace"
          ]
        },
        {
          "type": "service",
          "id": "analyzeFace",
          "url": "http://service-face-analyzer.project-dev.svc.cluster.local/compute",
          "input": {
            "image": "loop.cropFace.out.result"
          },
          "next": [
            "loopEnd"
          ]
        }
      ],
      "collect": {
        "analysis": "analyzeFace.out"
      }
    },
    {
      "type": "node",
      "id": "describe",
      "after": "nbFaces = len(loopFaces.out)\nif nbFaces == 0:\n  txt = 'No face detected in this image.'\nelse:\n  txt = str(nbFaces) + ' people detected in this image. '\n  for ana in loopFaces.out:\n    analysis = loopFaces.out[ana]\n    if len(analysis) == 0:\n      txt += 'One person that could not be identified. '\n    else:\n      txt += 'A {age} years old {race} {gender} that looks {emotion}. '.format(age=analysis['age'], race=analysis['dominant_race'], gender=analysis['gender'].lower(), emotion=analysis['dominant_emotion'])\nnode.out['description'] = txt",
      "next": [
        "faceDescrEnd"
      ]
    },
    {
      "type": "end",
      "id": "faceDescrEnd",
      "input": {
        "description": "describe.out.description"
      }
    }
  ]
}
